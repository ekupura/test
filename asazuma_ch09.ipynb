{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ekupura/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = Path(\"./data\")\n",
    "header = [\"source\", \"target\"]\n",
    "train = pd.read_table(dir_path / \"train.txt\", header=None, names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(dataframe, head=\"source\"):\n",
    "    counter = Counter()\n",
    "    for source in dataframe[head]:\n",
    "        words = word_tokenize(source)\n",
    "        counter.update(words)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word2id(counter):\n",
    "    sorted_counter = sorted(counter.items(), key=lambda x:x[1], reverse=True)\n",
    "    word2id = defaultdict(int)\n",
    "    for rank, (word, count) in enumerate(sorted_counter):\n",
    "        if count > 1:\n",
    "            word2id[word] = rank + 1\n",
    "    return word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label2id(dataframe, head=\"target\"):\n",
    "    target_set = set(dataframe[head])\n",
    "    label2id = defaultdict(int)\n",
    "    for idx, target in enumerate(target_set):\n",
    "        label2id[target] = idx\n",
    "    return label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = count_words(train)\n",
    "word2id = generate_word2id(counter)\n",
    "label2id = generate_label2id(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_converted_df(dataframe, word2id, label2id, source_head=\"source\", target_head=\"target\"):\n",
    "    converted_sources, converted_targets = [], []\n",
    "    for source, target in zip(dataframe[source_head], dataframe[target_head]):\n",
    "        words = word_tokenize(source)\n",
    "        converted_sources.append([word2id[word] for word in words])\n",
    "        converted_targets.append(label2id[target])\n",
    "        \n",
    "    converted_df = pd.DataFrame({source_head: converted_sources, target_head: converted_targets})\n",
    "    return converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_converted_df(train, word2id, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_table(dir_path / \"valid.txt\", header=None, names=header)\n",
    "valid_df = make_converted_df(valid, word2id, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(dir_path / \"test.txt\", header=None, names=header)\n",
    "test_df = make_converted_df(test, word2id, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3439, 126, 5118, 115, 6632, 37, 3440, 1261, 5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9, 6633, 644, 266, 2, 5120, 5121, 4126, 22, 7...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[94, 96, 295, 0, 6, 146, 20, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[679, 2272, 11, 679, 2272, 6, 0, 13, 0, 5, 776]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1795, 1, 1640, 224, 2, 6634, 1001, 27, 0, 10,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10667</th>\n",
       "      <td>[6351, 69, 35, 3492, 0, 5, 18, 0, 22, 420, 182...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10668</th>\n",
       "      <td>[3110, 1734, 0, 11, 7517, 17, 55, 8885, 7, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10669</th>\n",
       "      <td>[9, 0, 0, 447, 12, 849, 111, 18, 1448, 300]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10670</th>\n",
       "      <td>[6322, 1047, 0, 465, 2451, 12, 0, 127]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10671</th>\n",
       "      <td>[736, 7154, 2700, 442, 335, 21, 178, 5]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10672 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  target\n",
       "0      [3439, 126, 5118, 115, 6632, 37, 3440, 1261, 5...       0\n",
       "1      [9, 6633, 644, 266, 2, 5120, 5121, 4126, 22, 7...       2\n",
       "2                     [94, 96, 295, 0, 6, 146, 20, 0, 0]       2\n",
       "3        [679, 2272, 11, 679, 2272, 6, 0, 13, 0, 5, 776]       2\n",
       "4      [1795, 1, 1640, 224, 2, 6634, 1001, 27, 0, 10,...       0\n",
       "...                                                  ...     ...\n",
       "10667  [6351, 69, 35, 3492, 0, 5, 18, 0, 22, 420, 182...       2\n",
       "10668  [3110, 1734, 0, 11, 7517, 17, 55, 8885, 7, 0, ...       1\n",
       "10669        [9, 0, 0, 447, 12, 849, 111, 18, 1448, 300]       0\n",
       "10670             [6322, 1047, 0, 465, 2451, 12, 0, 127]       0\n",
       "10671            [736, 7154, 2700, 442, 335, 21, 178, 5]       2\n",
       "\n",
       "[10672 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[126, 59, 0, 0, 5, 13, 0, 329, 5533]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2990, 1508, 7502, 7503, 0, 1177, 411, 171, 50...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2448, 8199, 29, 28, 6610, 1592, 0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2778, 528, 19, 1797, 319, 2457, 41, 33, 3087,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1284, 0, 3464, 0, 2, 655, 1641, 5194]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>[500, 233, 64, 1655, 590, 1351, 21, 1811, 592,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>[328, 4669, 15, 4366, 992, 38, 20, 47, 23, 1034]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>[0, 282, 1, 256, 4466, 852, 1, 0, 1001, 7, 4203]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>[9, 0, 2444, 2, 0, 399, 6, 849, 1350, 853]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>[39, 35, 7225, 0, 8918, 657, 31, 0, 0, 7813, 6...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  target\n",
       "0                  [126, 59, 0, 0, 5, 13, 0, 329, 5533]       0\n",
       "1     [2990, 1508, 7502, 7503, 0, 1177, 411, 171, 50...       2\n",
       "2                   [2448, 8199, 29, 28, 6610, 1592, 0]       2\n",
       "3     [2778, 528, 19, 1797, 319, 2457, 41, 33, 3087,...       2\n",
       "4                [1284, 0, 3464, 0, 2, 655, 1641, 5194]       0\n",
       "...                                                 ...     ...\n",
       "1329  [500, 233, 64, 1655, 590, 1351, 21, 1811, 592,...       2\n",
       "1330   [328, 4669, 15, 4366, 992, 38, 20, 47, 23, 1034]       3\n",
       "1331   [0, 282, 1, 256, 4466, 852, 1, 0, 1001, 7, 4203]       0\n",
       "1332         [9, 0, 2444, 2, 0, 399, 6, 849, 1350, 853]       0\n",
       "1333  [39, 35, 7225, 0, 8918, 657, 31, 0, 0, 7813, 6...       2\n",
       "\n",
       "[1334 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[738, 0, 4, 1854, 915, 44, 17, 3158, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1352, 770, 4510, 19, 71, 0, 3234, 1, 43, 2344...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[912, 466, 1398, 58, 203, 12, 71, 134, 6, 341,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2470, 3549, 19, 2102, 1, 2225, 115, 21, 1708,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[377, 419, 0, 2589, 22, 8264, 5, 36, 252, 842]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>[3028, 167, 5, 0, 473, 482, 2131, 27, 2578, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>[1028, 317, 5305, 0, 316, 293, 852]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>[1717, 7391, 0, 1559, 4822, 1, 3034, 59, 172, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>[2103, 4620, 664, 2, 437, 3838, 2131, 41, 20, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>[100, 3218, 163, 1, 6329, 18, 173, 170, 31, 53...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  target\n",
       "0               [738, 0, 4, 1854, 915, 44, 17, 3158, 0]       1\n",
       "1     [1352, 770, 4510, 19, 71, 0, 3234, 1, 43, 2344...       0\n",
       "2     [912, 466, 1398, 58, 203, 12, 71, 134, 6, 341,...       3\n",
       "3     [2470, 3549, 19, 2102, 1, 2225, 115, 21, 1708,...       0\n",
       "4        [377, 419, 0, 2589, 22, 8264, 5, 36, 252, 842]       3\n",
       "...                                                 ...     ...\n",
       "1329     [3028, 167, 5, 0, 473, 482, 2131, 27, 2578, 0]       0\n",
       "1330                [1028, 317, 5305, 0, 316, 293, 852]       3\n",
       "1331  [1717, 7391, 0, 1559, 4822, 1, 3034, 59, 172, ...       3\n",
       "1332  [2103, 4620, 664, 2, 437, 3838, 2131, 41, 20, ...       3\n",
       "1333  [100, 3218, 163, 1, 6329, 18, 173, 170, 31, 53...       3\n",
       "\n",
       "[1334 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.rnn = nn.RNN(embedding_length, hidden_size, num_layers=1, bidirectional=False)\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None):\n",
    "        input_embeddings = self.word_embeddings(input_sentences)\n",
    "        input_embeddings = input_embeddings.permute(1, 0, 2)\n",
    "        if batch_size is None:\n",
    "            h_0 = torch.zeros(1, self.batch_size, self.hidden_size).to(device)\n",
    "        else:\n",
    "            h_0 =  torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        output, h_n = self.rnn(input_embeddings, h_0)\n",
    "        \n",
    "        h_n = h_n.permute(1, 0, 2)\n",
    "        h_n = h_n.squeeze(1)\n",
    "        logits = self.label(h_n)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.tensor(train_df[\"source\"][0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max(word2id.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2211,  0.1122, -0.1986,  0.0815]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(1, 4, 200, vocab_size, 200)\n",
    "model(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sources, targets):\n",
    "        self.len = len(sources)\n",
    "        self.sources = [torch.tensor(source)for source in sources]\n",
    "        self.targets = torch.tensor(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sources[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    sources = torch.t(nn.utils.rnn.pad_sequence([s[0] for s in data]))\n",
    "    targets = torch.tensor([s[1] for s in data])\n",
    "    return sources, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, batch_size):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.optim = torch.optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=0.001)\n",
    "        self.loss_fn = F.cross_entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def score(true, pred):\n",
    "        pred_cpu = torch.argmax(pred, dim=1).long().detach().cpu()\n",
    "        true_cpu = true.long().detach().cpu()\n",
    "        acc = accuracy_score(true_cpu, pred_cpu)\n",
    "        f1 = f1_score(true_cpu, pred_cpu, average=\"macro\")\n",
    "        return acc, f1\n",
    "\n",
    "    @staticmethod\n",
    "    def print_progress(prefix, epoch, loss, acc, f1):\n",
    "        args = (prefix, epoch + 1, loss, acc, f1)\n",
    "        print(\"Type: {}, Epoch: {}, Loss: {:.4f}, Acc: {:.4f}, F1: {:.4f}\".format(*args))\n",
    "\n",
    "    @staticmethod\n",
    "    def to_gpu(source, target):\n",
    "        return source.to(device), target.to(device)\n",
    "\n",
    "    def train_model(self, train_iter, epoch):\n",
    "        total_epoch_loss, total_epoch_acc, total_epoch_f1, steps = 0, 0, 0, 0\n",
    "        self.model.train()\n",
    "        for idx, (source, target) in enumerate(train_iter):\n",
    "            if source.size()[0] is not self.batch_size:\n",
    "                continue\n",
    "            source, target = self.to_gpu(source, target)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            prediction = self.model(source)\n",
    "            loss = self.loss_fn(prediction, target)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "            steps += 1\n",
    "            acc, f1 = self.score(target, prediction)\n",
    "\n",
    "            if steps % 100 == 0:\n",
    "                # self.print_progress(\"train\", epoch, loss.item(), acc, f1)\n",
    "                pass\n",
    "            \n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc\n",
    "            total_epoch_f1 += f1\n",
    "\n",
    "        n_iter = len(train_iter)\n",
    "        return total_epoch_loss / n_iter, total_epoch_acc / n_iter, total_epoch_f1 / n_iter\n",
    "\n",
    "\n",
    "    def eval_model(self, val_iter):\n",
    "        total_epoch_loss, total_epoch_acc, total_epoch_f1 = 0, 0, 0\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (source, target) in enumerate(val_iter):\n",
    "                source, target = self.to_gpu(source, target)\n",
    "                if (source.size()[0] is not self.batch_size):\n",
    "                    continue\n",
    "                prediction = self.model(source)\n",
    "                loss = self.loss_fn(prediction, target)\n",
    "                acc, f1 = self.score(target, prediction)\n",
    "\n",
    "                total_epoch_loss += loss.item()\n",
    "                total_epoch_acc += acc\n",
    "                total_epoch_f1 += f1\n",
    "\n",
    "        n_iter = len(val_iter)\n",
    "        return total_epoch_loss / n_iter, total_epoch_acc / n_iter, total_epoch_f1 / n_iter\n",
    "\n",
    "    def train(self, train, valid, test, n_iter=30):\n",
    "        min_val_loss = 1e+10\n",
    "        best_state_dict = None\n",
    "\n",
    "        self.model.to(device)\n",
    "        for epoch in range(n_iter):\n",
    "            train_loss, train_acc, train_f1 = self.train_model(train, epoch)\n",
    "            self.print_progress(\"train\", epoch, train_loss, train_acc, train_f1)\n",
    "            val_loss, val_acc, val_f1 = self.eval_model(valid)\n",
    "            self.print_progress(\"valid\", epoch, val_loss, val_acc, val_f1)\n",
    "\n",
    "            # save best model\n",
    "            if min_val_loss > val_loss:\n",
    "                min_val_loss = val_loss\n",
    "                best_state_dict = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        self.model.load_state_dict(best_state_dict)\n",
    "        test_loss, test_acc, test_f1 = self.eval_model(test)\n",
    "        self.print_progress(\"test_\", epoch, val_loss, val_acc, val_f1)\n",
    "\n",
    "        return best_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "output_size=4\n",
    "hidden_size=200\n",
    "embedding_length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(train_df[\"source\"], train_df[\"target\"])\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "valid_set = MyDataset(valid_df[\"source\"], valid_df[\"target\"])\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_set = MyDataset(test_df[\"source\"], test_df[\"target\"])\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max(word2id.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(batch_size=batch_size, output_size=output_size, hidden_size=hidden_size, vocab_size=vocab_size, embedding_length=embedding_length)\n",
    "trainer = Trainer(model, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: train, Epoch: 1, Loss: 0.9528, Acc: 0.6606, F1: 0.6606\n",
      "Type: valid, Epoch: 1, Loss: 0.7597, Acc: 0.7309, F1: 0.7309\n",
      "Type: train, Epoch: 2, Loss: 0.6456, Acc: 0.7737, F1: 0.7737\n",
      "Type: valid, Epoch: 2, Loss: 0.6662, Acc: 0.7511, F1: 0.7511\n",
      "Type: train, Epoch: 3, Loss: 0.4915, Acc: 0.8237, F1: 0.8237\n",
      "Type: valid, Epoch: 3, Loss: 0.6673, Acc: 0.7789, F1: 0.7789\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "output_size=4\n",
    "hidden_size=200\n",
    "embedding_length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(train_df[\"source\"], train_df[\"target\"])\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "valid_set = MyDataset(valid_df[\"source\"], valid_df[\"target\"])\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_set = MyDataset(test_df[\"source\"], test_df[\"target\"])\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(batch_size=batch_size, output_size=output_size, hidden_size=hidden_size, vocab_size=vocab_size, embedding_length=embedding_length)\n",
    "trainer = Trainer(model, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
